(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{287:function(e,s,a){"use strict";a.r(s);var r=a(14),c=Object(r.a)({},(function(){var e=this,s=e._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("h1",{attrs:{id:"docker出世"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#docker出世"}},[e._v("#")]),e._v(" docker出世")]),e._v(" "),s("p",[e._v("在互联网世界从web1.0迈入web2.0后，计算机网络发展进入了一个新的阶段。在这一阶段，让更多的用户方便快捷地使用网络服务成为急需解决的问题，与同时，一些大型公司也开始致力于开发大型计算能力的技术，为用户提供了更加强大的计算处理服务，云计算概念普及、应用。PaaS（Platform as a Service"),s("a",{attrs:{href:"https://baike.baidu.com/item/%E5%B9%B3%E5%8F%B0%E5%8D%B3%E6%9C%8D%E5%8A%A1/4329761",target:"_blank",rel:"noopener noreferrer"}},[e._v("平台即服务"),s("OutboundLink")],1),e._v("）作为云计算三个服务层次中的一种，同时发展壮大。")]),e._v(" "),s("p",[e._v("云计算概念刚开始普及的那段时期，主流用户普遍用法就是租一批 业务流程管理开发平台（AWS）或是云计算管理平台OpenStack的虚拟机，然后像管理物理服务器那样，用脚本或者手工的方式在这些机器上部署应用。在这个过程中，常会碰到一个令猿头秃的问题：云端虚拟机和本地环境不一致。")]),e._v(" "),s("p",[e._v("PaaS项目此时提供了“应用托管”的能力，可以帮助用户大规模部署应用到集群里。在PaaS发展的热潮中，各PaaS项目比的就是谁能更好地模拟本地服务器环境，能带来更好的“上云”体验。")]),e._v(" "),s("p",[e._v('这其中，一家名为 Cloud Foundry 的公司选择率先开源，迅速风靡市场。它的优势在于大大简化运维人员的部署操作，运维人员只需要在这些机器上部署一个 Cloud Foundry 项目，开发者只要执行一条命令（cf push "我的应用"）就能把本地的应用部署到云上，但仍未解决运维人员面对环境不一致所花费的大量人力问题。')]),e._v(" "),s("p",[e._v("因为一键部署虽然听起来很美妙，但这个打包过程着实痛苦：用户必须为每种语言、每种框架，甚至每个版本的应用维护一个打好的包。这个打包过程，没有任何章法可循，有时候明明在本地运行得好好的应用，却需要做很多修改和配置工作才能在 PaaS 里运行起来。而这些修改和配置，并没有什么经验可以借鉴，基本上得靠不断试错，直到你摸清楚了本地应用和远端 PaaS 匹配的“脾气”才能够搞定。")]),e._v(" "),s("p",[e._v("2013年，一个并不显眼的PaaS创业公司dotCloud，紧随其后选择了开源自家的一个项目：Docker。docker的出现，解决了打包这个根本性的问题，使得本地环境和云端环境的高度一致！而其解决方式，正是docker的创新之处，也是docker日后风靡云计算圈子的法宝--镜像。")]),e._v(" "),s("h1",{attrs:{id:"docker镜像"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#docker镜像"}},[e._v("#")]),e._v(" docker镜像")]),e._v(" "),s("p",[e._v("前面说docker解决了烦人的打包问题，那么它是如何解决的呢？")]),e._v(" "),s("p",[e._v("它直接打包了应用运行所需要的整个操作系统，这个压缩包里的文件内容跟你本地开发和测试环境用的操作系统是完全一样的，从而保证了本地环境和云端环境的高度一致。")]),e._v(" "),s("p",[e._v("举个栗子，假设你的应用在本地运行时，能看见的环境是 CentOS 7.2 操作系统的所有文件和目录，那么只要用 CentOS 7.2 的 ISO 做一个压缩包，再把你的应用可执行文件也压缩进去，那么无论在哪里解压这个压缩包，都可以得到与你本地测试时一样的环境。当然，你的应用也在里面！只要有这个压缩包在手，你就可以使用某种技术创建一个“容器”，在“容器”中解压这个压缩包，然后就可以运行你的程序了。")]),e._v(" "),s("p",[e._v("这里有一个问题：难道我每开发一个应用，或者升级一下现有的应用，都要重复制作一次镜像吗？")]),e._v(" "),s("p",[e._v("大家可能很容易想到一个解决办法：在制作镜像的时候，每做一步“有意义”的操作，就保存一个镜像出来，这样其他同事就可以按需求去用他需要的镜像了。")]),e._v(" "),s("p",[e._v("但是，一旦你的同事们修改了这个 镜像，新旧两个镜像之间就没有任何关系了。这样就导致极度的碎片化。")]),e._v(" "),s("p",[e._v("那进一步想想，既然这些修改都基于一个旧的镜像，我们能不能以增量的方式去做这些修改呢？这样做的好处就是，所有人都只需要维护相对于 base 镜像 修改的增量内容。")]),e._v(" "),s("p",[e._v("而事实上Docker就是基于此，做了一个小小创新：")]),e._v(" "),s("p",[e._v("Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层。")]),e._v(" "),s("p",[e._v("我们可以输入如下代码，进入镜像查看：")]),e._v(" "),s("p",[e._v("docker image inspect 镜像名")]),e._v(" "),s("p",[e._v("比如我查看redis镜像：")]),e._v(" "),s("p",[s("img",{attrs:{src:"https://pan.udolphin.com/files/image/2022/9/1a08f6da92709453490cf91e72be6605.png",alt:""}})]),e._v(" "),s("p",[e._v("可以看到这里有很多层（layers）。")]),e._v(" "),s("p",[e._v("而这些layer是、又分为三层：只读层，可读可写层，Init层。")]),e._v(" "),s("p",[e._v("其中，可读可写层，就是专门用来存放你修改 镜像 后产生的增量，无论是增、删、改，都发生在这里。而当我们使用完了这个被修改过的容器之后，还可以使用docker commit 和 push 指令，保存这个被修改过的可读写层，并上传到 Docker Hub上，供其他人使用；这个过程中，原先的只读层里的内容将不会有任何变化。")]),e._v(" "),s("p",[e._v("Init 层是 Docker 项目单独生成的一个内部层，它有什么用呢？"),s("br"),e._v("\n需要这样一层的原因是，用户往往需要在启动容器时写入一些指定的值比如 hostname，所以就需要在可读写层对它们进行修改。可是，这些修改往往只对当前的容器有效，我们并不希望执行 docker commit 时，把这些信息连同可读写层一起提交掉。所以，Docker 做法是，在修改了这些文件之后，以一个单独的层挂载了出来。而用户执行docker commit 只会提交可读写层，所以是不包含这些内容的。")]),e._v(" "),s("p",[e._v("可以看出，由于容器镜像的操作是增量式的，这样每次镜像拉取、推送的内容，比原本多个完整的操作系统的大小要小得多；而共享层的存在，可以使得所有这些容器镜像需要的总空间，也比每个镜像的总和要小。这样就使得基于容器镜像要比基于动则几个 GB 的虚拟机磁盘镜像的协作要敏捷得多。更重要的是，一旦这个镜像被发布，那么你在全世界的任何一个地方下载这个镜像，得到的内容都完全一致，可以完全复现这个镜像制作者当初的完整环境。这，就是容器技术“强一致性”的重要体现。")]),e._v(" "),s("h1",{attrs:{id:"容器"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#容器"}},[e._v("#")]),e._v(" 容器")]),e._v(" "),s("p",[s("img",{attrs:{src:"https://pan.3dlink.cn/files/image/2022/9/5e97bf21163727b99d62bed924ddb680.png",alt:""}})]),e._v(" "),s("p",[e._v("前面提到，当你有了docker镜像，你就可以使用某种技术创建一个“沙盒”，在“沙盒”中解压这个压缩包，然后就可以运行你的程序了。这里的沙盒，就是容器。")]),e._v(" "),s("p",[e._v("正如docker的logo上小鲸鱼背的集装箱一样，容器技术就像是集装箱，它可以将你的应用“装”起来，这样，应用与应用之间，就因为有了边界而不至于相互干扰，而被装进集装箱的应用，也可以被方便地搬来搬去。")]),e._v(" "),s("p",[e._v("容器技术其实并不是docker首创，它实际上是调用操作系统的 Cgroups 和 Namespace 机制为每一个应用单独创建一个称作“沙盒”的隔离环境，然后在“沙盒”中启动应用进程。")]),e._v(" "),s("p",[e._v("这也是前面提到的Cloud Foundry 的容器实现方式，以至于当时docker崛起时，Cloud Foundry 并未将之放在眼里，甚至忽略掉了docker镜像这个黑魔法。")]),e._v(" "),s("p",[e._v("接下来我们就来看看这个所谓Cgroups 和 Namespace 机制，看看容器到底是怎么一回事。")]),e._v(" "),s("h2",{attrs:{id:"进程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#进程"}},[e._v("#")]),e._v(" 进程")]),e._v(" "),s("p",[e._v("首先，我们从进程说起。我们知道，计算机只认识 0 和 1，所以无论用哪种语言编写这段代码，最后都需要通过某种方式翻译成二进制文件，才能在计算机操作系统中运行起来。而为了能够让这些代码正常运行，我们往往还要给它提供数据，比如我们有个加法程序所需要的输入文件。这些数据加上代码本身的二进制文件，放在磁盘上，就是我们平常所说的一个“程序”。然后，我们就可以在计算机上运行这个“程序”。首先，操作系统从“程序”中发现输入数据保存在一个文件中，所以这些数据就被会加载到内存中待命。同时，操作系统又读取到了计算加法的指令，这时，它就需要指示 CPU 完成加法操作。而 CPU 与内存协作进行加法计算，又会使用寄存器存放数值、内存堆栈保存执行的命令和变量。同时，计算机里还有被打开的文件，以及各种各样的 I/O 设备在不断地调用中修改自己的状态。就这样，一旦“程序”被执行起来，它就从磁盘上的二进制文件，变成了计算机内存中的数据、寄存器里的值、堆栈中的指令、被打开的文件，以及各种设备的状态信息的一个集合。像这样一个程序运起来后的计算机执行环境的总和，就是进程的动态表现。")]),e._v(" "),s("p",[e._v("所以，对于进程来说，它的静态表现就是程序，平常都安安静静地待在磁盘上；而一旦运行起来，它就变成了计算机里的数据和状态的总和，这就是它的动态表现。而容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。")]),e._v(" "),s("p",[e._v("所以说，说白了，"),s("strong",[e._v("容器也只是一种特殊的进程")]),e._v("，接下来我们一起来看看这个特殊进程是如何变成容器的样子的吧。")]),e._v(" "),s("p",[s("img",{attrs:{src:"https://pan.3dlink.cn/files/image/2022/9/576b3a374529494bdfc80a075a1742f8.png",alt:""}})]),e._v(" "),s("h3",{attrs:{id:"namespace"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#namespace"}},[e._v("#")]),e._v(" Namespace")]),e._v(" "),s("p",[e._v("Linux 在创建容器的时候，就会建出一个 PID Namespace，PID 其实就是进程的编号。")]),e._v(" "),s("p",[e._v("这个 PID Namespace，就是指每建立出一个 Namespace，就会单独对进程进行 PID 编号，每个 Namespace 的 PID 编号都从 1 开始。同时在这个 PID Namespace 中也只能看到 Namespace 中的进程，而且看不到其他 Namespace 里的进程。")]),e._v(" "),s("p",[e._v("这也就是说，如果有另外一个容器，那么它也有自己的一个 PID Namespace，而这两个 PID Namespace 之间是不能看到对方的进程的，这里就体现出了 Namespace 的作用：相互隔离。")]),e._v(" "),s("p",[e._v("这种机制，其实就是对被隔离应用的进程空间做了手脚，使得这些进程只能看到重新计算过的进程编号，")]),e._v(" "),s("p",[e._v("没错，就是一个障眼法。"),s("br"),e._v("\n在 Linux 系统中创建进程的系统调用是 clone()，比如：")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("int pid = clone(main_function, stack_size, SIGCHLD, NULL);  \n")])])]),s("p",[e._v("这个系统调用就会为我们创建一个新的进程，并且返回它的进程号 pid。")]),e._v(" "),s("p",[e._v("当我们用 clone() 系统调用创建一个新进程时，就可以在参数中指定 CLONE_NEWPID 参数，比如")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("int pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL);  \n")])])]),s("p",[e._v("这时，新创建的这个进程将会“看到”一个全新的进程空间，在这个进程空间里，它的 PID是 1。")]),e._v(" "),s("p",[e._v("除了我们刚刚用到的 PID Namespace，Linux 操作系统还提供了 Mount、UTS、IPC、Network 和 User 这些 Namespace，用来对各种不同的进程上下文进行“障眼法”操作。"),s("br"),e._v("\n比如，Mount Namespace，用于让被隔离进程只看到当前 Namespace 里的挂载点信息；Network Namespace，用于让被隔离进程看到当前 Namespace 里的网络设备和配置。"),s("br"),e._v("\n这就是 Linux 容器最基本的实现原理了。"),s("br"),e._v("\n还是那句话，"),s("strong",[e._v("容器，其实是一种特殊的进程而已。")])]),e._v(" "),s("h4",{attrs:{id:"对比虚拟机"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#对比虚拟机"}},[e._v("#")]),e._v(" 对比虚拟机")]),e._v(" "),s("p",[e._v("说起“为进程划分一个独立空间”，虚拟机也是干这事儿的，那虚拟机与容器有什么区别呢？")]),e._v(" "),s("p",[s("img",{attrs:{src:"https://pan.3dlink.cn/files/image/2022/9/f9d7a3682d095be3958d6d6c767f4fda.png",alt:""}})]),e._v(" "),s("p",[e._v("如上图所示，这幅图的左边，画出了虚拟机的工作原理。其中，名为 Hypervisor 的软件是虚拟机最主要的部分。它通过硬件虚拟化功能，模拟出了运行一个操作系统需要的各种硬件，比如CPU、内存、I/O 设备等等。然后，它在这些虚拟的硬件上安装了一个新的操作系统，图中是Guest OS。这样，用户的应用进程就可以运行在这个虚拟的机器中，它能看到的自然也只有 Guest OS的文件和目录，以及这个机器里的虚拟设备。")]),e._v(" "),s("p",[e._v("这就是为什么虚拟机也能将不同的应用进程相互隔离。")]),e._v(" "),s("p",[e._v("而这幅图的右边，则用一个名为 Docker Engine 的软件替换了 Hypervisor。可以看出，docker实际上就是把虚拟机的概念套在了容器上。这也是为什么，我们会把 Docker 项目称为“轻量级”虚拟化技术。")]),e._v(" "),s("p",[e._v("图中我们看到 Docker 在跟应用同级别并且靠边的位置。这意味着，用户运行在容器里的应用进程，跟宿主机上的其他进程一样，都由宿主机操作系统统一管理，只不过这些被隔离的进程拥有额外设置过的 Namespace 参数。而 Docker 项目在这里做的是旁路式的辅助和管理工作。")]),e._v(" "),s("p",[e._v("在理解了 Namespace 的工作方式之后，我们会发现，跟真实存在的虚拟机不同，在使用Docker 的时候，并没有一个真正的“Docker 容器”运行在宿主机里面。Docker 项目帮助用户启动的，还是原来的应用进程，只不过在创建这些进程时，Docker 为它们加上了各种各样的 Namespace 参数。这时，这些进程就会觉得自己是各自 PID Namespace 里的第 1 号进程，只能看到各自Mount Namespace 里挂载的目录和文件，只能访问到各自 Network Namespace 里的网络设备，就仿佛运行在一个个“容器”里面，与世隔绝。")]),e._v(" "),s("p",[e._v("而容器这种方式带来的好处是显而易见的。根据实验，一个运行着 CentOS 的 KVM 虚拟机启动后，在不做优化的情况下，虚拟机自己就需要占用 100~200 MB 内存。此外，用户应用运行在虚拟机里面，它对宿主机操作系统的调用就不可避免地要经过虚拟化软件的拦截和处理，这本身又是一层性能损耗，尤其对计算资源、网络和磁盘 I/O 的损耗非常大。相比之下，容器化后的用户应用，却依然还是一个宿主机上的普通进程，这就意味着这些因为虚拟化而带来的性能损耗都是不存在的；另一方面，使用 Namespace 作为隔离手段的容器并不需要单独的 Guest OS，这就使得容器额外的资源占用几乎可以忽略不计。")]),e._v(" "),s("h3",{attrs:{id:"cgroups"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#cgroups"}},[e._v("#")]),e._v(" Cgroups")]),e._v(" "),s("p",[e._v("前面我们说，对于Linux 容器来说，Cgroups 技术是用来制造约束的主要手段，而Namespace 技术则是用来修改进程视图的主要方法。")]),e._v(" "),s("p",[e._v("那我们已经通过 Linux Namespace 创建了一个“容器”，为什么还需要对容器做“限制”呢？")]),e._v(" "),s("p",[e._v("因为虽然容器内的第 1 号进程在“障眼法”的干扰下只能看到容器里的情况，但是宿主机上，它作为第 n 号进程与其他所有进程之间依然是平等的竞争关系。这就意味着，虽然第100 号进程表面上被隔离了起来，但是它所能够使用到的资源（比如 CPU、内存），却是可以随时被宿主机上的其他进程（或者其他容器）占用的。当然，这个第 n 号进程自己也可能把所有资源吃光，这显然不合理，而Linux Cgroups 就是 Linux 内核中用来为进程设置资源限制的一个重要功能。")]),e._v(" "),s("p",[e._v("Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等（Cgroups 还能够对进程进行优先级设置、审计，以及将进程挂起和恢复等操作）。")]),e._v(" "),s("p",[e._v("在说到资源限制前，我们先看看什么是资源，就拿我们最常说的CPU占用率来说。")]),e._v(" "),s("p",[e._v("一个CPU一般就只有两种状态，要么被占用，要么不被占用。当有多个进程要占用cpu的时候，那么操作系统在一个cpu核心上是进行分时处理的。")]),e._v(" "),s("p",[e._v("什么是分时处理呢，举个栗子，比如说，我们把一秒钟分成1000份，那么每一份就是1毫秒，假设现在有5个进程都要用cpu，那么我们就让它们5个轮着使用，比如一人一毫秒，那么1秒过后，每个进程只占用了这个CPU的200ms，使用率为20%。整体cpu使用比率为100%。")]),e._v(" "),s("p",[e._v("同理，如果只有一个进程占用，而且它只用了300ms，那么在这一秒的尺度看来，cpu的占用时间是30％。于是显示出来的状态就是占用30%的CPU时间。")]),e._v(" "),s("p",[e._v("这就是内核是如何看待和分配计算资源的。当然实际情况要比这复杂的多，但是基本思路就是这样。")]),e._v(" "),s("p",[e._v("接下来我们通过一组实践带你认识一下 Cgroups。在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下。在 Ubuntu 16.04 机器里，我们可以用 mount 指令把它们展示出来，这条命令是：")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("mount -t cgroup \ncpuset on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset) cpu on /sys/fs/cgroup/cpu type cgroup (rw,nosuid,nodev,noexec,relatime,cpu) cpuacct on /sys/fs/cgroup/cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct) blkio on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio) memory on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory) ...\n")])])]),s("p",[e._v("可以看到，在 /sys/fs/cgroup 下面有很多诸如 cpuset、cpu、 memory 这样的子目录，也叫子系统。这些都是这台机器当前可以被 Cgroups 进行限制的资源种类。而在子系统对应的资源种类下，可以看到该类资源具体可以被限制的方法。比如，对 CPU 子系统来说，我们就可以看到如下几个配置文件，这个指令是：")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("ls /sys/fs/cgroup/cpu cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us  cpu.shares notify_on_release cgroup.procs      cpu.cfs_quota_us  cpu.rt_runtime_us cpu.stat  tasks\n")])])]),s("p",[e._v("我们看到这个输出里有 cfs_period 和 cfs_quota 这样的关键词，他们通常成对使用，作用如下：")]),e._v(" "),s("p",[e._v("1、cpu.cfs_period_us：指定容器对CPU的使用多长时间重新做一次分配")]),e._v(" "),s("p",[e._v("2、cpu.cfs_quota_us：指在cpu.cfs_period_us周期内给分配多少时间给容器")]),e._v(" "),s("p",[e._v("这两个参数可以用来限制进程在长度为 cfs_period 的一段时间内，只能被分配到总量为 cfs_quota 的 CPU 时间。")]),e._v(" "),s("p",[e._v("这样的配置文件又如何使用呢？你需要在对应的子系统下面创建一个目录，比如，我们现在进入 /sys/fs/cgroup/cpu 目录下：")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("root@ubuntu:/sys/fs/cgroup/cpu$ mkdir container \nroot@ubuntu:/sys/fs/cgroup/cpu$ ls container/ cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us  cpu.shares notify_on_release cgroup.procs      cpu.cfs_quota_us  cpu.rt_runtime_us cpu.stat  tasks\n")])])]),s("p",[e._v("这个目录就称为一个“控制组”。操作系统会在新创建的 container 目录下，自动生成该子系统对应的资源限制文件。现在，我们在后台执行这样一条死循环脚本：")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("while : ; do : ; done & [1] 226\n")])])]),s("p",[e._v("根据它的输出，我们可以看到这个脚本在后台运行的进程号（PID）是 226。这样，我们可以用 top 指令来确认一下 CPU 有没有被打满：")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("top %Cpu0 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st\n")])])]),s("p",[e._v("在输出里可以看到，CPU 的使用率已经 100% 了（%Cpu0 :100.0 us）。而此时，我们可以通过查看 container 目录下的文件，看到 container 控制组里的 CPU quota 还没有任何限制（即：-1），CPU period 则是默认的 100 ms（100000 us）：")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us -1 $ cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us 100000\n")])])]),s("p",[e._v("接下来，我们可以通过修改这些文件的内容来设置限制。比如，向 container 组里的 cfs_quota 文件写入 20 ms（20000 us）：")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("echo 20000 > /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us\n")])])]),s("p",[e._v("这个操作意味着在每 100 ms 的时间里，被该控制组限制的进程只能使用 20 ms 的 CPU 时间，也就是说这个进程只能使用到 20% 的 CPU 带宽。接下来，我们把被限制的进程的 PID 写入 container 组里的 tasks 文件，上面的设置就会对该进程生效了：")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("echo 226 > /sys/fs/cgroup/cpu/container/tasks \n")])])]),s("p",[e._v("我们可以用 top 指令查看一下：")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("top %Cpu0 : 20.3 us, 0.0 sy, 0.0 ni, 79.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st\n")])])]),s("p",[e._v("可以看到，计算机的 CPU 使用率立刻降到了 20%（%Cpu0 : 20.3 us）。")]),e._v(" "),s("p",[e._v("除 CPU 子系统外，Cgroups 的每一个子系统都有其独有的资源限制能力，比如：blkio，为块设备设定I/O 限制，一般用于磁盘等设备；cpuset，为进程分配单独的 CPU 核和对应的内存节点；memory，为进程设定内存使用的限制。")]),e._v(" "),s("p",[e._v("Linux Cgroups 的设计简单粗暴地理解，它就是一个子系统目录加上一组资源限制文件的组合。而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。而至于在这些控制组下面的资源文件里填上什么值，就靠用户执行 docker run 时的参数指定了，比如这样一条命令：")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash\n")])])]),s("p",[e._v("在启动这个容器后，我们可以通过查看 Cgroups 文件系统下，CPU 子系统中，“docker”这个控制组里的资源限制文件的内容来确认：")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_period_us 100000 $ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_quota_us 20000\n")])])]),s("p",[e._v("这就意味着这个 Docker 容器，只能使用到 20% 的 CPU 带宽。")]),e._v(" "),s("h1",{attrs:{id:"总结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[e._v("#")]),e._v(" 总结")]),e._v(" "),s("p",[e._v("好啦，以上就是我们对Docker的初步认知啦。")]),e._v(" "),s("p",[e._v("在这篇文章里，我们探寻了镜像是通过分层的概念将协作开发变得轻盈敏捷，并且再也不用担心环境不一致的问题；")]),e._v(" "),s("p",[e._v("同时对比了Linux Namespace 作为隔离手段的优势和劣势，对比 Linux 容器跟虚拟机技术的不同，明确了“容器只是一种特殊的进程”这个结论；")]),e._v(" "),s("p",[e._v("最后我们通过实验模拟了 Docker 项目创建容器限制的过程，明确了容器在做好了隔离工作之后，如何通过 Linux Cgroups 实现资源的限制。")]),e._v(" "),s("p",[e._v("通过以上讲述，我们现在应该能够理解，一个正在运行的 Docker 容器，其实就是一个启用了多个 Linux Namespace 的应用进程，这个进程的环境基于镜像，而这个进程能够使用的资源量，则受 Cgroups 配置的限制。")]),e._v(" "),s("h1",{attrs:{id:"kubernetes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#kubernetes"}},[e._v("#")]),e._v(" Kubernetes")]),e._v(" "),s("p",[e._v("经过前面对容器就阐述，我们其实可以发现"),s("strong",[e._v("重要的不是容器，而是容器的编排")]),e._v("。")]),e._v(" "),s("p",[e._v("docker虽然解决了打包的问题，但无法取代PaaS完成大规模部署应用的职责。所以，docker公司在2014年发布了Swarm项目，该项目基于docker自身的容器管理对外提供集群管理服务。")]),e._v(" "),s("p",[e._v("但事实上，脱胎于谷歌Borg项目的Kubernetes，才是目前容器编排市场的老大。")]),e._v(" "),s("p",[e._v("Kubernetes 项目要着重解决的问题，则来自于 Borg 的研究人员在论文中提到的一个非常重要的观点：")]),e._v(" "),s("p",[e._v("运行在大规模集群中的各种任务之间，实际上存在着各种各样的关系。这些关系的处理，才是作业编排和管理系统最困难的地方。")]),e._v(" "),s("p",[e._v("Kubernetes 项目所擅长的，是按照用户的意愿和整个系统的规则，完全自动化地处理好容器之间的各种关系。这种功能，就是我们经常听到的一个概念：编排。")]),e._v(" "),s("p",[e._v("所以说，Kubernetes 项目的本质，是为用户提供一个具有普遍意义的容器编排工具。")]),e._v(" "),s("p",[e._v("容器技术这样一个新生事物，完全重塑了整个云计算市场的形态。它不仅催生出了一批年轻有为的容器技术人，更培育出了一个具有相当规模的开源基础设施技术市场。")]),e._v(" "),s("p",[e._v("在这个市场里，不仅有 Google、Microsoft 等技术巨擘们厮杀至今，更有无数的国内外创业公司前仆后继。而在国内，甚至连以前对开源基础设施领域涉足不多的 BAT、蚂蚁、滴滴这样的巨头们，也都从 AI、云计算、微服务、基础设施等维度多管齐下，争相把容器和Kubernetes 项目树立为战略重心之一。就在这场因“容器”而起的技术变革中，Kubernetes 项目已然成为容器技术的事实标准，重新定义了基础设施领域对应用编排与管理的种种可能。")]),e._v(" "),s("p",[e._v("不妨想象一下 Kubernetes 就是未来的 Linux 操作系统。在这个云计算以前所未有的速度迅速普及的世界里，Kubernetes 项目很快就会像操作系统一样，成为每一个技术从业者必备的基础知识。")])])}),[],!1,null,null,null);s.default=c.exports}}]);