(window.webpackJsonp=window.webpackJsonp||[]).push([[45],{317:function(v,_,a){"use strict";a.r(_);var t=a(14),s=Object(t.a)({},(function(){var v=this,_=v._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("h2",{attrs:{id:"散列表"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#散列表"}},[v._v("#")]),v._v(" 散列表")]),v._v(" "),_("p",[v._v("对于散列表来说，我们可以先想一下这样的一个问题，word编辑器我想大家应该都用过把，那你有没有留意过他的单词拼写功能呢？一旦我们在word里输入一个错误的英文单词，它就会用标红的方式i提示“拼写错误”。")]),v._v(" "),_("p",[v._v("那大家有没有想过这样的一个单词拼写纠正功能是怎么实现的呢？")]),v._v(" "),_("h3",{attrs:{id:"散列表运行原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#散列表运行原理"}},[v._v("#")]),v._v(" 散列表运行原理")]),v._v(" "),_("p",[v._v("首先我们来看什么是散列表？英文叫做HashTable，通常来说hash我们可以翻译为散列，所以可以翻译为散列表，也可以音译成哈希表。")]),v._v(" "),_("p",[v._v("昨天我们讲数组的时候提到了一个数组的杀手锏般的特性叫做随机访问，散列表的出现就是基于数组按照下标可以随机访问的这个特性实现的，也可以理解为散列表就是数组的一种扩展，是由数组演化而来的。")]),v._v(" "),_("p",[v._v("大家可以想象这样一个场景，假如一个学校要开一场运动会，有90名选手要参加这个运动会， 那为了方便记录成绩和区分，我们会让运动员在胸口和背后都贴上一个编号，比方说编号是从1-90，每一个编号都对应了一个选手的信息，我们如果想希望通过编号去快速的查找到选手的信息，我们会怎么做呢？")]),v._v(" "),_("p",[v._v("相信大家第一反应一定是我们可以用数组去存，我们把选手的编号和数组的下标对应起来，这样我们就可以利用数组的"),_("strong",[v._v("随机访问特性")]),v._v("来以O(1)时间复杂度的方式获取到这个选手的信息。")]),v._v(" "),_("p",[v._v("那么这个例子其实已经有了一些散列表的思想了，选手的编号与数组的下标是一一映射的。那如果我们把这个问题升级一下，现在我们要将选手的编号弄的再复杂一些，我们要加入这个人的学号，年级，班级等等，最后两位是选手的编号，那么这时候其中一位选手的编号可能是'43216527'，像这样的一串数字，这时候我们要怎么办呢？")]),v._v(" "),_("p",[v._v("其实还是一样对吧，因为最后两位是选手的编号，那我们每次都取这串数字的最后两位作为选手与数组下标的映射就可以了，这时候我们就需要一个方法帮我们把这个事情给做了，这个方法要做的就是我们会传入给它一个key，然后它会给我返回一个index，我们通过这个index可以直接利用数组的随机访问的特性，去访问到这个选手的信息。")]),v._v(" "),_("p",[v._v("那么这样的处理方法就是散列思想了，选手的编号我们叫做key，我们用它可以来标识到一个选手，我们把将参赛选手的编号转为数组下标映射的方法称作散列函数，我们将散列函数转换完的值叫做散列值，或者叫哈希值。")]),v._v(" "),_("p",[_("img",{attrs:{src:"https://pan.udolphin.com/files/image/2021/10/375c24d5ea23b8a3981af61f8324207a.png",alt:"image.png"}})]),v._v(" "),_("p",[v._v("就像图中这样，我们将各种各样的key传入hash function，然后我们可以得到一个哈希值，通过这个哈希值我们可以直接访问到table里面的元素。")]),v._v(" "),_("p",[v._v("通过这个例子我们可以总结一下散列表的运行原理：")]),v._v(" "),_("p",[v._v("当我们插入一个元素的时候，通过给散列函数传key，可以得到一个与数组下标对应的散列值，我们可以直接将元素存入到数组的下标位置。")]),v._v(" "),_("p",[v._v("当我们查找一个元素的时候，还是通过散列函数解析key得到与数组下标对应的散列值，我们利用数组支持按照下标随机访问的时候，时间复杂度为O(1)的这个特性，可以直接从数组中获取散列值对应的位置的数据。")]),v._v(" "),_("h3",{attrs:{id:"散列函数"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#散列函数"}},[v._v("#")]),v._v(" 散列函数")]),v._v(" "),_("p",[v._v("那我们要如何设计一个散列函数呢？我在这里列了散列函数要遵循的三个基本要求：")]),v._v(" "),_("ol",[_("li",[v._v("散列函数计算得到的散列值是一个非负整数")]),v._v(" "),_("li",[v._v("如果key1 == key2，那hash(key1) == hash(key2)")]),v._v(" "),_("li",[v._v("如果key1 != key2，那hash(key1) != hash(key2)")])]),v._v(" "),_("p",[v._v("第一条其实很好理解对吧，因为数组下标是从0开始的，所以散列函数生成的散列值也必须是非负数。")]),v._v(" "),_("p",[v._v("第二点其实也没什么问题，如果我们使用了相同的key，散列函数肯定要解析出相同的散列值，不然我们存进去的数据要怎么访问呢？对吧，也是在情理之中。")]),v._v(" "),_("p",[v._v("第三条可能有点问题，不同的key经过散列函数计算一定要返回一个不同的值，乍一看好像没什么问题，但是其实想找到一个每一个key 都可以对应一个散列值的函数，基本上是不存在的。即便上是MD5、SHA这样著名的哈希算法也没有办法避免这种情况。")]),v._v(" "),_("h3",{attrs:{id:"为什么无法避免散列冲突"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#为什么无法避免散列冲突"}},[v._v("#")]),v._v(" 为什么无法避免散列冲突？")]),v._v(" "),_("p",[v._v("大家观察散列算法可以发现一个规律，那就是散列算法会将任意长度的输入转换为固定长度的输出算法，那么这个固定长度其实就是一个值域，所以说散列算法一定是一个压缩算法，就像图中这样：\n"),_("img",{attrs:{src:"https://pan.udolphin.com/files/image/2021/10/c8b919ed926bb4a586f5302caf0a2dfb.png",alt:"image.png"}})]),v._v(" "),_("p",[v._v("那到这里其实就很好理解了，我们一直将大值域的东西压缩成小值域的东西，那么冲突就是无法避免的，这里可以用鸽巢原理或者叫抽屉原理，假设有10个鸽巢，现在有11只鸽子，无论我们分配的多么平均，总是会有一个鸽巢里有两只鸽子，这是避免不了的。")]),v._v(" "),_("h3",{attrs:{id:"散列冲突的解决方案"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#散列冲突的解决方案"}},[v._v("#")]),v._v(" 散列冲突的解决方案")]),v._v(" "),_("p",[v._v("既然我们没有办法避免散列冲突，那我们能做的就只有想办法降低散列冲突的概率，这里我主要分享两种解决散列冲突的方案，一个是开放寻址法，另一个是链表法。")]),v._v(" "),_("h2",{attrs:{id:"开放寻址法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#开放寻址法"}},[v._v("#")]),v._v(" 开放寻址法")]),v._v(" "),_("h3",{attrs:{id:"线性探测法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#线性探测法"}},[v._v("#")]),v._v(" 线性探测法")]),v._v(" "),_("p",[v._v("开放寻址法的核心思想就是，如果出现了散列冲突，我们就重新探测一个位置，将其插入。我们从一个比较简单的探测方法开始，线性探测法。\n"),_("img",{attrs:{src:"https://pan.udolphin.com/files/image/2021/10/cbc5bba2f6583b64bebc27e373357ca7.png",alt:"image.png"}})]),v._v(" "),_("p",[v._v("我们先来看线性探测法的插入方法，这是一个大小为10的散列表，红色的方块代表已经有元素在里面了，绿色的表示还是空余的可以用来存放元素的位置。")]),v._v(" "),_("p",[v._v("现在我们要把x插入到这个散列表里，首先我们通过散列函数将key解析成散列值，之后我们发现它落在了下标为7的位置，但是下标为7的位置已经有数据，所以要继续往下找，找到头之后会重新从散列表下标为0的位置继续寻找，直到找到了下标为2的这个位置，把x就插入进去了。")]),v._v(" "),_("p",[_("img",{attrs:{src:"https://pan.udolphin.com/files/image/2021/10/f25723b9120b1aadd5a3c4ff482ffb9b.png",alt:"image.png"}})]),v._v(" "),_("p",[v._v("在散列表中的查找过程其实有些类似刚刚的插入过程，当我们在一个散列表中查找一个元素的时候，他有可能存在有可能不存在，如果是数组的话，不会出现冲突，我们直接使用随机访问的特性就可以拿到数据，但是散列表的话可能会出现冲突。")]),v._v(" "),_("p",[v._v("比如说我们要去查y这个元素，计算之后他的散列值是7，然后我们需要对比这个元素和我们要查找的元素是否相等，如果相等说明我们找的就是它；如果不相等，那我们就要继续往下去一个一个的找，找到第三个元素的时候发现一致了，就找到了。如果一直遍历到一个空闲位置都没有找到这个元素，那就认为这个元素不在这个散列表里。")]),v._v(" "),_("p",[_("img",{attrs:{src:"https://pan.udolphin.com/files/image/2021/10/19cef25a848b15368c9da24b72c0483e.png",alt:"image.png"}})]),v._v(" "),_("p",[v._v("接下来是线性探测法的删除，对于删除操作这里有些东西需要注意，比方说我们要删除下标为1的数据后，那1的位置就是空了，这时候我们再去查找y的时候会发现，我们还是先从7开始，然后往后走8、9、0、1，走到这里的时候就走不下去了，因为这之后下标为1的地方已经变成了空，那么即便这个散列表里有y这个元素，也会被认为这个元素已经不在了。")]),v._v(" "),_("p",[v._v("所以怎么解决这个问题呢？其实我们已经不止一次的遇到过这种问题了对吧，从最开始的数组批量删除，我们就提出过一种方案，那就是标记法，我们把要删除的元素标记上，但是并不真的删除，最后再一起删除，那这里我们也可以用同样的方法，那就是先把要删除的元素标记上，这时候再遍历到这里的时候，因为看到是deleted标记所以会继续往下找，这样就就不会导致我们之前的查找算法失效了。")]),v._v(" "),_("p",[v._v("到这里其实我们不难发现，线性探测法其实存在很大的问题，当散列表中插入的数据越来越多的时候，冲突发生的可能就越来越大，但是空闲位置会越来越少，导致探测时间会越来越久，极端情况下，我们需要探查整个散列表，不管是插入、查找、还是删除的时间复杂度都是O(n)。")]),v._v(" "),_("h2",{attrs:{id:"链表法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#链表法"}},[v._v("#")]),v._v(" 链表法")]),v._v(" "),_("p",[v._v("那除了线性探测之外还有一种更加常用的散列表解决冲突的方法，就是链表法，相比开放寻址法，它要简单很多。\n"),_("img",{attrs:{src:"https://pan.udolphin.com/files/image/2021/10/940dfc8c082faf5208dda3da56f923b7.png",alt:"image.png"}})]),v._v(" "),_("p",[v._v("我们可以看这张图，在散列表中，每个“桶”或者“槽”会对应一条链表，所有散列值相同的元素我们都会放到对应的桶位的链表中。")]),v._v(" "),_("p",[v._v("当插入的时候，我们还是只需要通过散列函数计算出散列值对应的槽位，然后将数据插入到链表中就可以了，所以插入的时间复杂度是O(1)。")]),v._v(" "),_("p",[v._v("当查找和删除一个元素的时候，我们同样还是用散列函数计算出对应的槽位，然后遍历列表查找和删除。那请问这时候查找和删除的时间复杂度分别是多少呢？")]),v._v(" "),_("p",[v._v("其实这两个操作的时间复杂度跟链表长度k成正比，也就是O(k)。对于散列比较均匀的散列函数来说，理论上，k=n/m，其中n表示散列中数据的个数，m表示散列表中“槽”的个数。")]),v._v(" "),_("p",[v._v("在散列平均的前提下，k=n/m，如果n = 10，m=10，那k=1，一个萝卜一个坑，如果n=20，m=10，那说明每个链表里都要存两个值，那么最坏情况下，每次都要去拿第二个值，")]),v._v(" "),_("h2",{attrs:{id:"小结"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[v._v("#")]),v._v(" 小结")]),v._v(" "),_("p",[v._v("那最后我们来解答开篇提出的问题，word文档中，单词拼写检查功能是如何实现的？")]),v._v(" "),_("p",[v._v("常用的英文单词有20万个左右，假设单词的平均长度是10个字母，平均一个单词占用10个字节的内存空间，那20万英文单词大约占2MB的存储空间，就算再放大10倍，即便是20MB。对于现在的计算机来说这个大小是完全可以放在内存里的。所以我们可以用散列表来存储整个英文单词词典。")]),v._v(" "),_("p",[v._v("当用户输入某个英文单词时，我们拿用户输入的单词去散列表中查找，如果查到就是正确的，如果没查到，就提示可能有误，有了散列表我们可以轻松的实现快速判断是否存在拼写错误。")]),v._v(" "),_("p",[v._v("当我们输入一个单词的时候，它会通过我们设计好的散列函数，将我们输入的单词转换成对应数组的索引，然后利用数组的随机访问特性，快速的去查找校验是否有这样的一个单词。")]),v._v(" "),_("h2",{attrs:{id:"二分查找"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#二分查找"}},[v._v("#")]),v._v(" 二分查找")]),v._v(" "),_("p",[v._v("针对有序集合的查找算法，二分查找，折半查找。二分查找的思想其实很简单，但是想灵活的用好却不太容易，我们还是先来开一个思考题：")]),v._v(" "),_("p",[v._v("假设我们有1000万个证书数据，每个数据占8个字节，如何设计数据结构和算法，快速判断某个整数是否出现在这1000万个数中，我们希望这个功能不要占用太多的内存空间，最多不要超过100MB。")]),v._v(" "),_("h3",{attrs:{id:"二分思想"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#二分思想"}},[v._v("#")]),v._v(" 二分思想")]),v._v(" "),_("p",[v._v("二分查找是一种非常简单易懂的快速查找算法，生活中到处可见。比如说，我们现在来做一个猜字游戏。我随机写一个 0 到 99 之间的数字，然后你来猜我写的是什么。猜的过程中，你每猜一次，我就会告诉你猜的大了还是小了，直到猜中为止。你来想想，如何快速猜中我写的数字呢？假设我写的数字是 23，你可以按照下面的步骤来试一试。（如果猜测范围的数字有偶数个，中间数有两个，就选择较小的那个。）")]),v._v(" "),_("p",[_("img",{attrs:{src:"https://pan.udolphin.com/files/image/2021/10/ab258cc18c0e4340703e09d4a7ed75e6.png",alt:"image.png"}})]),v._v(" "),_("p",[v._v("7 次就猜出来了，是不是很快？这个例子用的就是二分思想，按照这个思想，即便我让你猜的是 0 到 999 的数字，最多也只要 10 次就能猜中。不信的话，你可以试一试。")]),v._v(" "),_("p",[v._v("这是一个生活中的例子，我们现在回到实际的开发场景中。假设有 1000 条订单数据，已经按照订单金额从小到大排序，每个订单金额都不同，并且最小单位是元。我们现在想知道是否存在金额等于 19 元的订单。如果存在，则返回订单数据，如果不存在则返回 null。")]),v._v(" "),_("p",[v._v("最简单的办法当然是从第一个订单开始，一个一个遍历这 1000 个订单，直到找到金额等于 19 元的订单为止。但这样查找会比较慢，最坏情况下，可能要遍历完这 1000 条记录才能找到。那用二分查找能不能更快速地解决呢？")]),v._v(" "),_("p",[v._v("为了方便讲解，我们假设只有 10 个订单，订单金额分别是：8，11，19，23，27，33，45，55，67，98。")]),v._v(" "),_("p",[_("img",{attrs:{src:"https://pan.udolphin.com/files/image/2021/10/71a1893d78bf83982bdcfb0aa42ffad4.png",alt:"image.png"}})]),v._v(" "),_("p",[v._v("还是利用二分思想，每次都与区间的中间数据比对大小，缩小查找区间的范围。为了更加直观，我画了一张查找过程的图。其中，low 和 high 表示待查找区间的下标，mid 表示待查找区间的中间元素下标。")]),v._v(" "),_("p",[v._v("看懂这两个例子，你现在对二分的思想应该掌握得妥妥的了。二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。")]),v._v(" "),_("h3",{attrs:{id:"o-logn-惊人的查找速度"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#o-logn-惊人的查找速度"}},[v._v("#")]),v._v(" O(logn) 惊人的查找速度")]),v._v(" "),_("p",[v._v("二分查找是一种非常高效的查找算法，高效到什么程度呢？我们来分析一下它的时间复杂度。")]),v._v(" "),_("p",[v._v("我们假设数据大小是 n，每次查找后数据都会缩小为原来的一半，也就是会除以 2。最坏情况下，直到查找区间被缩小为空，才停止。")]),v._v(" "),_("p",[v._v("不难想象，这是一个等比数列。其中 n/2k=1 时，k 的值就是总共缩小的次数。而每一次缩小操作只涉及两个数据的大小比较，所以，经过了 k 次区间缩小操作，时间复杂度就是 O(k)。通过 n/2k=1，我们可以求得 k=log2n，所以时间复杂度就是 O(logn)。")]),v._v(" "),_("p",[v._v("二分查找是我们目前为止遇到的第一个时间复杂度为 O(logn) 的算法。如果大家有兴趣看到堆、二叉树的操作等等，它们的时间复杂度也是 O(logn)。对于 O(logn) 这种对数时间复杂度。这是一种极其高效的时间复杂度，有的时候甚至比时间复杂度是常量级 O(1) 的算法还要高效。为什么这么说呢？")]),v._v(" "),_("p",[v._v("因为 logn 是一个非常“恐怖”的数量级，即便 n 非常非常大，对应的 logn 也很小。比如 n 等于 2 的 32 次方，这个数很大了吧？大约是 42 亿。也就是说，如果我们在 42 亿个数据中用二分查找一个数据，最多需要比较 "),_("strong",[v._v("32 次")]),v._v("。")]),v._v(" "),_("p",[v._v("我们前面讲过，用大 O 标记法表示时间复杂度的时候，会省略掉常数、系数和低阶。对于常量级时间复杂度的算法来说，O(1) 有可能表示的是一个非常大的常量值，比如 O(1000)、O(10000)。所以，常量级时间复杂度的算法有时候可能还没有 O(logn) 的算法执行效率高。")]),v._v(" "),_("p",[v._v("反过来，对数对应的就是指数。有一个非常著名的“阿基米德与国王下棋的故事”，你可以自行搜索一下，感受一下指数的“恐怖”。这也是为什么我们说，指数时间复杂度的算法在大规模数据面前是无效的。")]),v._v(" "),_("h3",{attrs:{id:"二分查找的非递归实现"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#二分查找的非递归实现"}},[v._v("#")]),v._v(" 二分查找的非递归实现")]),v._v(" "),_("p",[_("img",{attrs:{src:"https://pan.udolphin.com/files/image/2021/10/71580eb588699c1187b4e27e011d016e.png",alt:"image.png"}})]),v._v(" "),_("h3",{attrs:{id:"二分查找的局限"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#二分查找的局限"}},[v._v("#")]),v._v(" 二分查找的局限")]),v._v(" "),_("p",[v._v("前面我们分析过，二分查找的时间复杂度是 O(logn)，查找数据的效率非常高。不过，并不是什么情况下都可以用二分查找，它的应用场景是有很大局限性的。那什么情况下适合用二分查找，什么情况下不适合呢？")]),v._v(" "),_("p",[_("strong",[v._v("首先，二分查找依赖的是顺序表结构，简单点说就是数组。")])]),v._v(" "),_("p",[v._v("那二分查找能否依赖其他数据结构呢？比如链表。答案是不可以的，主要原因是二分查找算法需要按照下标随机访问元素。我们在数组和链表那两节讲过，数组按照下标随机访问数据的时间复杂度是 O(1)，而链表随机访问的时间复杂度是 O(n)。所以，如果数据使用链表存储，二分查找的时间复杂就会变得很高。")]),v._v(" "),_("p",[v._v("二分查找只能用在数据是通过顺序表来存储的数据结构上。如果你的数据是通过其他数据结构存储的，则无法应用二分查找。")]),v._v(" "),_("p",[_("strong",[v._v("其次，二分查找针对的是有序数据。")])]),v._v(" "),_("p",[v._v("二分查找对这一点的要求比较苛刻，数据必须是有序的。如果数据没有序，我们需要先排序。前面章节里我们讲到，排序的时间复杂度最低是 O(nlogn)。所以，如果我们针对的是一组静态的数据，没有频繁地插入、删除，我们可以进行一次排序，多次二分查找。这样排序的成本可被均摊，二分查找的边际成本就会比较低。")]),v._v(" "),_("p",[v._v("但是，如果我们的数据集合有频繁的插入和删除操作，要想用二分查找，要么每次插入、删除操作之后保证数据仍然有序，要么在每次二分查找之前都先进行排序。针对这种动态数据集合，无论哪种方法，维护有序的成本都是很高的。")]),v._v(" "),_("p",[v._v("所以，二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中。针对动态变化的数据集合，二分查找将不再适用。那针对动态数据集合，如何在其中快速查找某个数据呢？别急，等到二叉树那一节我会详细讲。")]),v._v(" "),_("p",[_("strong",[v._v("再次，数据量太小不适合二分查找。")])]),v._v(" "),_("p",[v._v("如果要处理的数据量很小，完全没有必要用二分查找，顺序遍历就足够了。比如我们在一个大小为 10 的数组中查找一个元素，不管用二分查找还是顺序遍历，查找速度都差不多。只有数据量比较大的时候，二分查找的优势才会比较明显。")]),v._v(" "),_("p",[v._v("不过，这里有一个例外。如果数据之间的比较操作非常耗时，不管数据量大小，我都推荐使用二分查找。比如，数组中存储的都是长度超过 300 的字符串，如此长的两个字符串之间比对大小，就会非常耗时。我们需要尽可能地减少比较次数，而比较次数的减少会大大提高性能，这个时候二分查找就比顺序遍历更有优势。")]),v._v(" "),_("p",[_("strong",[v._v("最后，数据量太大也不适合二分查找。")])]),v._v(" "),_("p",[v._v("二分查找的底层需要依赖数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间连续，对内存的要求比较苛刻。比如，我们有 1GB 大小的数据，如果希望用数组来存储，那就需要 1GB 的连续内存空间。")]),v._v(" "),_("p",[v._v("注意这里的“连续”二字，也就是说，即便有 2GB 的内存空间剩余，但是如果这剩余的 2GB 内存空间都是零散的，没有连续的 1GB 大小的内存空间，那照样无法申请一个 1GB 大小的数组。而我们的二分查找是作用在数组这种数据结构之上的，所以太大的数据用数组存储就比较吃力了，也就不能用二分查找了。")]),v._v(" "),_("h3",{attrs:{id:"小结-2"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#小结-2"}},[v._v("#")]),v._v(" 小结")]),v._v(" "),_("p",[v._v("二分查找的理论知识你应该已经掌握了。我们来看下开篇的思考题：如何在 1000 万个整数中快速查找某个整数？")]),v._v(" "),_("p",[v._v("这个问题并不难。我们的内存限制是 100MB，每个数据大小是 8 字节，最简单的办法就是将数据存储在数组中，内存占用差不多是 80MB，符合内存的限制。借助今天讲的内容，我们可以先对这 1000 万数据从小到大排序，然后再利用二分查找算法，就可以快速地查找想要的数据了。")]),v._v(" "),_("p",[v._v("看起来这个问题并不难，很轻松就能解决。实际上，它暗藏了“玄机”。如果你对数据结构和算法有一定了解，知道散列表、二叉树这些支持快速查找的动态数据结构。你可能会觉得，用散列表和二叉树也可以解决这个问题。实际上是不行的。先对这 1000 万数据从小到大排序，然后再利用二分查找算法，就可以快速地查找想要的数据了。")]),v._v(" "),_("p",[v._v("虽然大部分情况下，用二分查找可以解决的问题，用散列表、二叉树都可以解决。但是，我们后面会讲，不管是散列表还是二叉树，都会需要比较多的额外的内存空间。如果用散列表或者二叉树来存储这 1000 万的数据，用 100MB 的内存肯定是存不下的。而二分查找底层依赖的是数组，除了数据本身之外，不需要额外存储其他信息，是最省内存空间的存储方式，所以刚好能在限定的内存大小下解决这个问题。")]),v._v(" "),_("h2",{attrs:{id:"总结"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("今天我们学习了散列表和二分查找的知识，先是了解了散列思想，然后了解了散列函数相关知识，之后我们一起了解了两个解决散列冲突的方法，随后我们学习了一种对于有序数据非常高效的查找算法，叫做二分查找，我们了解了二分查找的思想，最后又看到了二分查找的局限。\n如果这篇文章对你有帮助的话，给我点个赞吧\n我是数字办的王子炀\n期待与你们共同成长！")])])}),[],!1,null,null,null);_.default=s.exports}}]);