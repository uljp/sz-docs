## 为什么需要复杂度分析？

你可能会有些疑惑，我把代码跑一遍，通过统计、监控，就能得到算法执行的时间和占用的内存大小。为什么还要做时间、空间复杂度分析呢？这种分析方法能比我实实在在跑一遍得到的数据更准确吗？
首先，我可以肯定地说，你这种评估算法执行效率的方法是正确的。很多数据结构和算法书籍还给这种方法起了一个名字，叫事后统计法。但是，这种统计方法有非常大的局限性。

### 事后统计法的局限

**1. 测试结果非常依赖测试环境**
  
测试环境中硬件的不同会对测试结果有很大的影响。比如，我们拿同样一段代码，分别用 Intel Core i9 处理器和 Intel Core i3 处理器来运行，不用说，i9 处理器要比 i3 处理器执行的速度快很多。还有，比如原本在这台机器上 a 代码执行的速度比 b 代码要快，等我们换到另一台机器上时，可能会有截然相反的结果。

**2. 测试结果受数据规模的影响很大**

后面我们会讲排序算法，我们先拿它举个例子。对同一个排序算法，待排序数据的有序度不一样，排序的执行时间就会有很大的差别。极端情况下，如果数据已经是有序的，那排序算法不需要做任何操作，执行时间就会非常短。除此之外，如果测试数据规模太小，测试结果可能无法真实地反映算法的性能。比如，对于小规模的数据排序，插入排序可能反倒会比快速排序要快。就像JS，V8中对于长度小于10的数组采用的是插入排序，对于大于10的数组会使用快排。

### 所以我们需要的是什么？

> 我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法。

在优化代码之前我们首先要确定的是指标，如果你的指标是语义化，那么你的优化方案就是命名和重构还有函数式编程；如果你的指标是性能，那么你的优化方案就是降低时间空间复杂度，提升性能。可如果你不知道如果去评估代码的执行效率，那就没有办法做这方面的优化。

## 大O复杂度表示法
 
算法的执行效率，粗略地讲，就是算法代码执行的时间。但是，如何在不运行代码的情况下，用“肉眼”得到一段代码的执行时间呢？

这里有段非常简单的代码，求 1,2,3...n 的累加和。现在，我就带你一块来估算一下这段代码的执行时间。
![image.png](https://pan.udolphin.com/files/image/2021/10/78b15d1fc5e6d549278d80bef7fddf7d.png)

从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：**读数据-运算-写数据**。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为** unit_time**。在这个假设的基础之上，这段代码的总执行时间是多少呢？

第 2、3 行代码分别需要 1 个 unit_time 的执行时间，第 4、5 行都运行了 n 遍，所以需要 2n*unit_time 的执行时间，所以这段代码总的执行时间就是 (2n+2)*unit_time。可以看出来，**所有代码的执行时间 T(n) 与每行代码的执行次数成正比**。

![image.png](https://pan.udolphin.com/files/image/2021/10/7c6dec466e0bf2a7121accbd340c1eb4.png)

按照这个思路，我们继续再来看这段代码。
![image.png](https://pan.udolphin.com/files/image/2021/10/6fa6e32aa42d09260f8526b985eaab3e.png)
我们依旧假设每个语句的执行时间是 unit_time。那这段代码的总执行时间 T(n) 是多少呢？
第 2、3、4 行代码，每行都需要 1 个 unit_time 的执行时间
第 5、6 行代码循环执行了 n 遍，需要 2n * unit_time 的执行时间
第 7、8 行代码循环执行了 n^2 遍，所以需要 2n^2 * unit_time 的执行时间。
所以，整段代码总的执行时间 T(n) = (2n^2+2n+3)*unit_time。


尽管我们不知道 unit_time 的具体值，但是通过这两段代码执行时间的推导过程，我们可以得到一个非常重要的规律，那就是，**所有代码的执行时间 T(n) 与每行代码的执行次数 f(n) 成正比**。
![image.png](https://pan.udolphin.com/files/image/2021/10/ba6199deaf778a497359b1c7c7030b1e.png)
我们可以把这个规律总结成一个公式。注意，大 O 就要登场了！

> T(n) = O(f(n))

我来具体解释一下这个公式。其中，T(n) 我们已经讲过了，它表示代码执行的时间；n 表示数据规模的大小；f(n) 表示每行代码执行的次数总和。因为这是一个公式，所以用 f(n) 来表示。公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。
![image.png](https://pan.udolphin.com/files/image/2021/10/a9a759bf4e3da8694b2e60740ec61ba6.png)

![image.png](https://pan.udolphin.com/files/image/2021/10/b4885e945064a15f16103a8137ab3bd0.png)
所以，第一个例子中的 T(n) = O(2n+2)，第二个例子中的 T(n) = O(2n2+2n+3)。这就是大 O 时间复杂度表示法。大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作**渐进时间复杂度（asymptotic time complexity）**，简称时间复杂度。

当 n 很大时，你可以把它想象成 10000、100000。而公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：**T(n) = O(n)； T(n) = O(n2)**。

## 时间复杂度分析

### 分析原则： 
- 只关注循环执行次数最多的一段代码
- 加法法则：总复杂度等于量级最大的那段代码的复杂度
- 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

### 1. 只关注循环次数最多的一段代码

刚才有说过，大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，**我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了**。这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。

### 2. 加法法则： 总复杂度等于量级最大的那段代码的复杂度
我这里还有一段代码。你可以先试着分析一下，然后再往下看跟我的分析思路是否一样。
![image.png](https://pan.udolphin.com/files/image/2021/10/cefe821f831c279edfe061b3c1ecb64a.png)
这个代码分为三部分，分别是求 sum_1、sum_2、sum_3。我们可以分别分析每一部分的时间复杂度，然后把它们放到一块儿，再取一个量级最大的作为整段代码的复杂度。

第一段的时间复杂度是多少呢？这段代码循环执行了 100 次，所以是一个常量的执行时间，跟 n 的规模无关。

即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟 n 无关，照样也是常量级的执行时间。当 n 无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，**它表示的是一个算法执行效率与数据规模增长的变化趋势**，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。

那第二段代码和第三段代码的时间复杂度是多少呢？答案是 O(n) 和 O(n2)，你应该能容易就分析出来，我就不啰嗦了。

综合这三段代码的时间复杂度，我们取其中最大的量级。所以，整段代码的时间复杂度就为 O(n2)。也就是说：总的时间复杂度就等于量级最大的那段代码的时间复杂度。那我们将这个规律抽象成公式就是：

![image.png](https://pan.udolphin.com/files/image/2021/10/e396698b587ce8a95c493889eacc8ed7.png)

### 乘法法则： 嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
我刚讲了一个复杂度分析中的加法法则，这儿还有一个乘法法则。类比一下，你应该能“猜到”公式是什么样子的吧？

如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 

> T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n)).

也就是说，假设 T1(n) = O(n)，T2(n) = O(n2)，则 T1(n) * T2(n) = O(n3)。落实到具体的代码上，我们可以把乘法法则看成是嵌套循环，我举个例子给你解释一下。

![image.png](https://pan.udolphin.com/files/image/2021/10/8e7d59dca8c50a0217640af93d842d06.png)

我们单独看 cal() 函数。假设 f() 只是一个普通的操作，那第 4～6 行的时间复杂度就是，T1(n) = O(n)。但 f() 函数本身不是一个简单的操作，它的时间复杂度是 T2(n) = O(n)，所以，整个 cal() 函数的时间复杂度就是，T(n) = T1(n) * T2(n) = O(n*n) = O(n2)。

## 几种常见的时间复杂度实例分析
虽然代码千差万别，但是常见的复杂度量级并不多。我稍微总结了一下，这些复杂度量级几乎涵盖了你今后可以接触的所有代码的复杂度量级。
![image.png](https://pan.udolphin.com/files/image/2021/10/1051e668cd84281432052caee3041451.png)
对于刚罗列的复杂度量级，我们可以粗略地分为两类，多项式量级和非多项式量级。其中，非多项式量级只有两个：O(2n) 和 O(n!)。

我们把时间复杂度为非多项式量级的算法问题叫作 NP（Non-Deterministic Polynomial，非确定多项式）问题。

当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。因此，关于 NP 时间复杂度我就不展开讲了。我们主要来看几种常见的多项式时间复杂度。

### 1.O(1)
![image.png](https://pan.udolphin.com/files/image/2021/10/f3e7e3bcdef1305013cc600334cd0d92.png)

我稍微总结一下，只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，**一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)**。

### 2.O(logn)、O(nlogn)
对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。我通过一个例子来说明一下。
![image.png](https://pan.udolphin.com/files/image/2021/10/ac5e0b31eb104658452de12c89238eeb.png)

根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。

从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于 n 时，循环结束。还记得我们高中学过的等比数列吗？实际上，变量 i 的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的：
![image.png](https://pan.udolphin.com/files/image/2021/10/267da242ebd95975089c135abdac11b7.png)

所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了。通过 2x=n 求解 x 这个问题我们想高中应该就学过了，我就不多说了。x=log2n，所以，这段代码的时间复杂度就是 O(log2n)。
现在，我把代码稍微改下，你再看看，这段代码的时间复杂度是多少？
![image.png](https://pan.udolphin.com/files/image/2021/10/31c21c9863c6980d58e384b506b51420.png)

根据我刚刚讲的思路，很简单就能看出来，这段代码的时间复杂度为 O(log3n)。
实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。为什么呢？

我们知道，对数之间是可以互相转换的，log3n 就等于 log32 * log2n，所以 O(log3n) = O(C * log2n)，其中 C=log32 是一个常量。基于我们前面的一个理论：在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))。所以，O(log2n) 就等于 O(log3n)。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 O(logn)。
![image.png](https://pan.udolphin.com/files/image/2021/10/723590595fbc5d1be7427bce019483fb.png)

如果你理解了我前面讲的 O(logn)，那 O(nlogn) 就很容易理解了。还记得我们刚讲的乘法法则吗？如果一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就是 O(nlogn) 了。而且，O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)。

### 3. O(m+n)、O(m*n)
我们再来讲一种跟前面都不一样的时间复杂度，代码的复杂度**由两个数据的规模**来决定。老规矩，先看代码！
![image.png](https://pan.udolphin.com/files/image/2021/10/93ee4323305456eba72dcb71b0bcf6d2.png)

从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。

针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。

## 空间复杂度分析

前面我们讲过，时间复杂度的全称是**渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系**。类比一下，空间复杂度全称就是**渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系**。

我还是拿具体的例子来给你说明。（这段代码有点“傻”，一般没人会这么写，我这么写只是为了方便给大家举例解释。）

![image.png](https://pan.udolphin.com/files/image/2021/10/9553b80dd6edd6cd36c01306da9efcf5.png)

跟时间复杂度分析一样，我们可以看到，第 2 行代码中，我们申请了一个空间存储变量 i，但是它是常量阶的，跟数据规模 n 没有关系，所以我们可以忽略。第 3 行申请了一个大小为 n 的 int 类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 O(n)。
我们常见的空间复杂度就是 O(1)、O(n)、O(n2 )，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多。所以，对于空间复杂度，掌握刚我说的这些内容已经足够了。

### 小结
复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，也可以粗略地表示，越高阶复杂的算法，执行效率也就越低。常见的复杂度并不多，从低阶到高阶有： O(1)、O(logn)、O(n)、O(nlogn)、O(n2)。
![image.png](https://pan.udolphin.com/files/image/2021/10/a51bdf1a9c64a47980e6b6757485c6b0.png)
**复杂度分析并不难，关键在于多练**。 之后讲后面的内容时，我还会带你详细地分析每一种数据结构和算法的时间、空间复杂度。只要多练，到后面每次看到代码的时候，简单的一眼就能看出其复杂度，难的稍微分析一下就能得出答案。

## 最好最坏情况分析

我们继续讲四个复杂度分析方面的知识点，**最好情况时间复杂度（best case time complexity）、最坏情况时间复杂度（worst case time complexity）、平均情况时间复杂度（average case time complexity）、均摊时间复杂度（amortized time complexity）**。如果这几个概念你都能掌握，那对你来说，复杂度分析这部分内容就没什么大问题了。

### 最好、最坏情况时间复杂度

我们先用之前的知识分析一下下面这段代码的时间复杂度：
![image.png](https://pan.udolphin.com/files/image/2021/10/64aff857c0dd8f33257ce4c78c023e98.png)

你应该可以看出来，这段代码要实现的功能是，在一个无序的数组（array）中，查找变量 x 出现的位置。如果没有找到，就返回 -1。按照上节课讲的分析方法，这段代码的复杂度是 O(n)，其中，n 代表数组的长度。
我们在数组中查找一个数据，并不需要每次都把整个数组都遍历一遍，因为有可能中途找到就可以提前结束循环了。但是，这段代码写得不够高效。我们可以这样优化一下这段查找代码。

![image.png](https://pan.udolphin.com/files/image/2021/10/d9a09d0c06f2ed3fa11fc52cce06fff4.png)

这个时候，问题就来了。我们优化完之后，这段代码的时间复杂度还是 O(n) 吗？很显然，咱们上一节讲的分析方法，解决不了这个问题。

因为，要查找的变量 x 可能出现在数组的任意位置。如果数组中第一个元素正好是要查找的变量 x，那就不需要继续遍历剩下的 n-1 个数据了，那时间复杂度就是 O(1)。但如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。所以，不同的情况下，这段代码的时间复杂度是不一样的。

为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念：**最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度**。

顾名思义，**最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度**。就像我们刚刚讲到的，在最理想的情况下，要查找的变量 x 正好是数组的第一个元素，这个时候对应的时间复杂度就是最好情况时间复杂度。

同理，**最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度**。就像刚举的那个例子，如果数组中没有要查找的变量 x，我们需要把整个数组都遍历一遍才行，所以这种最糟糕情况下对应的时间复杂度就是最坏情况时间复杂度。

### 平均情况时间复杂度

我们都知道，最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，我们需要引入另一个概念：**平均情况时间复杂度，后面我简称为平均时间复杂度**。

平均时间复杂度又该怎么分析呢？我还是借助刚才查找变量 x 的例子来给你解释。

要查找的变量 x 在数组中的位置，有 n+1 种情况：在数组的 0～n-1 位置中和不在数组中。我们把每种情况下，**查找需要遍历的元素个数累加起来**，到这里还没完，还有一种x并不在数组中的可能性，这时候仍会把n个元素都遍历一遍，所以我们可以得到这样的一段表达式，再使用一些我们初中学过的知识，可以把这段表达式化简，最后这段代码的时间复杂度就是这样：
![image.png](https://pan.udolphin.com/files/image/2021/10/316089f396a36bcf7e05cc2533cad14d.png)

我们知道，时间复杂度的大 O 标记法中，可以省略掉系数、低阶、常量，所以，咱们把刚刚这个公式简化之后，得到的平均时间复杂度就是 O(n)。

这个结论虽然是正确的，但是**计算过程稍微有点儿问题**。究竟是什么问题呢？我们刚讲的这 n+1 种情况，出现的概率并不是一样的。

我们来具体分析一下（这里要稍微用到一点概率论的知识），我们知道，要查找的变量 x，要么在数组里，要么就不在数组里。这两种情况对应的概率统计起来很麻烦，为了方便你理解，我们假设在数组中与不在数组中的概率都为 1/2。另外，要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。所以，根据**概率乘法法则**，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。

因此，前面的推导过程中存在的最大问题就是，没有将各种情况发生的概率考虑进去。如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了这样：

![image.png](https://pan.udolphin.com/files/image/2021/10/6de51afe6c9221358c19b0932dc46488.png)

这个值就是概率论中的加权平均值，也叫作期望值，所以平均时间复杂度的全称应该叫**加权平均时间复杂度或者期望时间复杂度**。

引入概率之后，前面那段代码的加权平均值为 (3n+1)/4。用大 O 表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是 O(n)。

你可能会说，平均时间复杂度分析好复杂啊，还要涉及概率论的知识。实际上，**在大多数情况下，我们并不需要区分最好、最坏、平均情况时间复杂度三种情况**。像我们上一节课举的那些例子那样，很多时候，我们使用一个复杂度就可以满足需求了。**只有同一块代码在不同的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分**。

### 均摊时间复杂度

到此为止，你应该已经掌握了算法复杂度分析的大部分内容了。下面我们来讲一个更加高级的概念，**均摊时间复杂度**，以及它对应的分析方法，**摊还分析（或者叫平摊分析）**。

均摊时间复杂度，听起来跟平均时间复杂度有点儿像。对于初学者来说，这两个概念确实非常容易弄混。我前面说了，大部分情况下，我们并不需要区分最好、最坏、平均三种复杂度。平均复杂度只在某些特殊情况下才会用到，而均摊时间复杂度应用的场景比它更加特殊、更加有限。

老规矩，我还是借助一个具体的例子来帮助你们理解。（当然，这个例子只是我为了方便讲解想出来的，实际上没人会这么写。）

![image.png](https://pan.udolphin.com/files/image/2021/10/7d11a32d47d9ad2e8a10f31cc2ca54f3.png)

我先来解释一下这段代码。这段代码实现了一个往数组中插入数据的功能。当数组满了之后，也就是代码中的 count == array.length 时，我们用 for 循环遍历数组求和，并清空数组，将求和之后的 sum 值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。

那这段代码的时间复杂度是多少呢？你可以先用我们刚讲到的三种时间复杂度的分析方法来分析一下。
最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为 count 的位置就可以了，所以最好情况时间复杂度为 O(1)。
最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为 O(n)。

那平均时间复杂度是多少呢？答案是 O(1)。我们还是可以通过前面讲的概率论的方法来分析。

假设数组的长度是 n，根据数据插入的位置的不同，我们可以分为 n 种情况，每种情况的时间复杂度是 O(1)。除此之外，还有一种“额外”的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是 O(n)。而且，这 n+1 种情况发生的概率一样，都是 1/(n+1)。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是O(1)。

至此为止，前面的最好、最坏、平均时间复杂度的计算，理解起来应该都没有问题。但是这个例子里的平均复杂度分析其实并不需要这么复杂，不需要引入概率论的知识。这是为什么呢？我们先来对比一下这个 insert() 的例子和前面那个 find() 的例子，你就会发现这两者有很大差别。

首先，find() 函数在极端情况下，复杂度才为 O(1)。但 insert() 在大部分情况下，时间复杂度都为 O(1)。只有个别情况下，复杂度才比较高，为 O(n)。这是 insert()第一个区别于 find() 的地方。

我们再来看第二个不同的地方。对于 insert() 函数来说，O(1) 时间复杂度的插入和 O(n) 时间复杂度的插入，出现的频率是非常有规律的，而且有一定的前后时序关系，一般都是一个 O(n) 插入之后，紧跟着 n-1 个 O(1) 的插入操作，循环往复。

所以，针对这样一种特殊场景的复杂度分析，我们并不需要像之前讲平均复杂度分析方法那样，找出所有的输入情况及相应的发生概率，然后再计算加权平均值。

针对这种特殊的场景，我们引入了一种更加简单的分析方法：**摊还分析法**，通过摊还分析得到的时间复杂度我们起了一个名字，叫**均摊时间复杂度**。

那究竟如何使用摊还分析法来分析算法的均摊时间复杂度呢？

我们还是继续看在数组中插入数据的这个例子。每一次 O(n) 的插入操作，都会跟着 n-1 次 O(1) 的插入操作，所以把耗时多的那次操作均摊到接下来的 n-1 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 O(1)。这就是均摊分析的大致思路。你都理解了吗？

均摊时间复杂度和摊还分析应用场景比较特殊，所以我们并不会经常用到。为了方便你理解、记忆，我这里简单总结一下它们的应用场景。如果你遇到了，知道是怎么回事儿就行了。

### 小结
对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在**前后连贯的时序关系**，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。

尽管很多数据结构和算法书籍都花了很大力气来区分平均时间复杂度和均摊时间复杂度，但其实我个人认为，均摊时间复杂度就是一种特殊的平均时间复杂度，我们没必要花太多精力去区分它们。你最应该掌握的是它的分析方法，摊还分析。至于分析出来的结果是叫平均还是叫均摊，这只是个说法，并不重要。

## 递归的复杂度分析

在学习了时间空间复杂度，学习了最好最坏情况分析，让我们进入实战，通过一道简单的小题目去分析一下最让我们头疼的递归的复杂度，同一道题目，同样使用递归算法，有的同学会写出O(n)的代码，有的同学会写出O(logn)的代码。

我们来看这样一道面试题，**求x的n次方**

如果在你面试的时候，面试官叫你写一个可以用于计算x的n次方的方法，最直观的或者说最容易想到的方法就是通过一个for循环求出结果，我们可能会写出这样一段代码：
![image.png](https://pan.udolphin.com/files/image/2021/10/a4cc4daf01285f744ec9dae09fc143f6.png)
不难看出这段代码的时间复杂度是O(n)，这时候面试官会说，有没有执行效率更好的发算法呢？

这时候你会想到，比O(n)复杂度更让人满意的就是O(logn)，那这题考察的就是递归了，ok那我用递归改造一下这个算法，代码可能会被改成这个样子
![image.png](https://pan.udolphin.com/files/image/2021/10/b67c69b9f7ff87951a67210561de9139.png)

大家可以看一下这段代码的时间复杂度是多少呢？

有些同学看到之后是不是就会想到是O(logn)了呢？

递归算法的时间复杂度要怎么计算呢？

> 递归算法的时间复杂度 = 递归的次数 * 每次递归中的操作次数

那我们可以再来看看这段代码递归了多少次呢？

每次执行n-1，递归了n次，所以时间复杂度是O(n)，每次进行了什么操作呢？进行了一个乘法操作，乘法操作的时间复杂度是O(1)，所以最后**这段代码的时间复杂度就是O(n)**。

那不对啊，显然没有达到我们的预期，于是又改进了一下，写出了这样的代码

![image.png](https://pan.udolphin.com/files/image/2021/10/7acfd1ac0df937959f1215ba42c3ffe7.png)

那么这份代码的时间复杂度又是多少呢？

我们来分析一下，首先看递归执行了多少次呢？

我们可以把递归抽象成一颗满二叉树，刚刚这段算法呢我们可以抽象成这样的一颗满二叉树，为了方便表示，我们就把n看作是16，就是这样的一棵树，节点数表示几个x相乘
![image.png](https://pan.udolphin.com/files/image/2021/10/79a19d62faa52b99516b55ebd4aa3472.png)

当前这颗二叉树就是求x的n次方，n为16的时候，进行了多少次乘法运算呢？

这棵树上的没一个节点就代表着一次递归相乘的操作，所以执行了多少次递归，就看这棵树上有多少颗节点.

熟悉二叉树的话应该知道如何求满二叉树的节点数量，就想这样一张图

![image.png](https://pan.udolphin.com/files/image/2021/10/ce6c9686decfb90b7e09cea4960de8fe.png)
我们可以发现这样一个公式就是，也就是等比数列求和公式，满二叉树的节点个数等于，2的n次方-1。

这时我们不难得出一个公式，对于深度m来说
> n = 16
2^3 + 2^2 + 2^1 + 2^0 = 15
2^m + 2^m-1 + ... + 2^0 = 2^m+1 - 1
m = log2n - 1
那么总节点数就是n - 1

时间复杂度忽略到常数项 -1 之后，这个**递归算法的时间复杂度依然是O(n)**。对的，没错，依然是O(n)。

那么这个算法仍然没有达到我们想优化的预期，想要优化到O(logn)
这是我们可以发现刚刚的代码中，是不是有哪些地方比较冗余呢？
经过精简之后，我们可以得到这样的代码
![image.png](https://pan.udolphin.com/files/image/2021/10/550fd09157790ce7f35b429061f3ac32.png)

这时候我们再看一下这份代码的时间复杂度是多少呢？

首先还是看他递归了多少次，可以看到这里渐渐有一个递归调用，而且每次都是n/2，所以这里我们一共调用了以2为底n的对数次。

其次看具体操作，每次都执行了一次乘法操作，这也是一个常数项的操作，所以这段递归算法的时间复杂度才是**真真正正的O(logn)**！

## 总结
今天我们学习了复杂度分析的方法，学习了时间复杂度分析和空间复杂度分析，之后又进一步的学习了最好最快情况时间复杂度分析，还有平均时间复杂度分析和均摊时间复杂度分析，并且学习了一种分析方法叫做摊还分析法。最后我们亲手通过我们学习的复杂度的分析方式，成功的将一段时间复杂度为O(n)的代码优化到了O(logn)！
如果这篇文章对你有帮助的话，给我点个赞吧！
我是数字办的王子炀～
期待与你们共同成长！～